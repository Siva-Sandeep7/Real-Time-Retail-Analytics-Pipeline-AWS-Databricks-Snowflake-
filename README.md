# ğŸ“¡ Real-Time Retail Data Pipeline: End-to-End Cloud Architecture

This project simulates and processes real-time retail orders with a fully orchestrated cloud-native architecture.

Data flows from a **web uploader or Python generator â†’ Amazon S3 â†’ Databricks (for transformation) â†’ Snowflake (as data warehouse) â†’ Power BI (for visualization)** â€” all automated via **Dockerized Apache Airflow**.

---

## âš™ï¸ Key Features

- ğŸ” Real-time data ingestion via Kinesis Firehose  
- ğŸ§¾ CSV data upload through a web interface  
- ğŸ”„ Transformations handled by Databricks (PySpark)  
- ğŸ“‚ Raw and Processed storage in Amazon S3  
- ğŸ§Š Final warehousing in Snowflake  
- ğŸ“Š BI Dashboards using Power BI  
- ğŸ³ Automated workflows containerized with Docker  
- ğŸ—‚ï¸ Orchestration handled via Apache Airflow DAGs  


---

## ğŸ› ï¸ Tech Stack

| Layer              | Tools Used                             |
|--------------------|-----------------------------------------|
| Ingestion           | Python, Web App, AWS Kinesis Firehose  |
| Staging & Storage   | Amazon S3 (raw-zone & processed-zone)  |
| Transformation      | Databricks (Apache Spark, PySpark)     |
| Orchestration       | Apache Airflow (Dockerized)            |
| Data Warehouse      | Snowflake                              |
| BI & Visualization  | Power BI                               |

---

## ğŸš€ Setup Instructions

1. **Upload CSV Data**  
   - Use the web interface or `python_realtime_generator.py`

2. **Raw Storage on S3**  
   - Uploads store data in CSV format to the raw-zone

3. **Databricks Transformation**  
   - Transforms data and writes to processed-zone in S3

4. **Load into Snowflake**  
   - Uses `COPY INTO` SQL for efficient loading

5. **Visualize in Power BI**  
   - Connect Power BI to Snowflake for live dashboards

6. **Automation**  
   - All steps orchestrated with Dockerized Airflow DAGs

---

---

## ğŸ“Š Dashboard Sample

Power BI displays:

- âœ… Total Orders  
- ğŸ¬ Store-wise Sales  
- ğŸ’µ Revenue Trends  
- ğŸ“¦ Item-wise Distribution  
- â±ï¸ Real-time timestamps  

---

## ğŸ’¡ Learning Outcomes

- ğŸ”§ Built an end-to-end real-time data pipeline  
- ğŸ§  Understood lakehouse architecture  
- ğŸ¤– Automated ETL workflows using Airflow  
- âš¡ Implemented real-time ingestion via Kinesis Firehose  
- ğŸ“ˆ Visualized clean data in Power BI  

---

## ğŸ™ Acknowledgements

Thanks to:

- ğŸŒ AWS Free Tier  
- ğŸ”¥ Databricks Community Edition  
- â„ï¸ Snowflake Free Trial  
- ğŸ’™ Stack Overflow  

---

## ğŸ“¬ Connect with Me

- ğŸ”— [LinkedIn](https://www.linkedin.com/in/siva-sandeep/)

---

## ğŸ·ï¸ Tags

`#AWS` `#Snowflake` `#Databricks` `#Docker` `#Airflow` `#Kinesis` `#S3` `#PowerBI`  
`#Python` `#ETL` `#DataEngineering` `#RealTimeAnalytics`
